Service Level Objectives Document
Service name: Banking API 
Service description: A banking API that simulates banking operations. A customer can apply for an account, view their balance, and make withdrawals and deposits. An employee can approve or deny accounts and view account balances for their customers.
Authors: Aaron Schroeder & Jeremy Engelsman
Date: 6/17/2022

SLIs:
	API: 
		HTTP Request Latency

			Requests taking less than 1 seconds / all requests
			Requests taking less than 0.5 seconds / all requests
			Requests taking less than 0.25 seconds / all requests
			
			ex:
                  sum(rate(Request_Latency_seconds_bucket{purpose="metrics",le="0.25"}[7d])) by (job)
                /
                  sum(rate(Request_Latency_seconds_count[7d])) by (job)


		Error rate

			All HTTP5XX codes / All Successful HTTP requests

			ex:
                sum(rate(jetty_server_requests_seconds_count{container="banking-api-app-deployment", status=~"5..", uri!="/metrics", uri!="NOT_FOUND"}[7d]))
                /
                sum(rate(jetty_server_requests_seconds_count{container="banking-api-app-deployment", status!="5..", uri!="/metrics", uri!="NOT_FOUND"}[7d]))


		Availability

			!HTTP5XX codes / all http requests

			ex:
                sum(rate(jetty_server_requests_seconds_count{container="banking-api-app-deployment", status!~"5..", uri!="/metrics", uri!="NOT_FOUND"}[7d]))
                /
                sum(rate(jetty_server_requests_seconds_count{container="banking-api-app-deployment", uri!="/metrics", uri!="NOT_FOUND"}[7d]))
		
		Throughput:
			Test?

	    Burn Rate:

	        In this case we calculated a running burn rate using a formula we found. (https://docs.datadoghq.com/monitors/service_level_objectives/burn_rate/)
	        Burn rates are complex, and have many considerations. This is just one (admittedly poor) way to do this.
	        This number will tell us if we are on track to exceed our error budget as defined by our error rate SLO.
	        This is agnostic to an error budget, because the error budget is based on a projection of load (i.e. 5000 requests a week.)

	        Burn rate = observed error rate
	                    /
	                    ideal error rate

	        ex: a value of 1.1 would tell us that we are, at a particular polled window of time, on track to break our SLO.

		
	Database:
		Latency:

			Requests taking less than 0.5 seconds / all requests
			Requests taking less than 0.3 seconds / all requests
			Requests taking less than 0.2 seconds / all requests

		Error rate:

			All SQL based 500s  / all successful http requests 
			or
			All failed database connections / All database connections

1 Week Window for Each SLO
SLOs:
	API:
		HTTP Request Latency:
			99% of requests < 1 seconds
			90% of requests < 0.5 seconds
			50% of requests < 0.25 seconds
		
		Availability:
			99%

		Error Rate:
		    between 99% and 99.9%

		Throughput:
			Test?

	
	Database:
		Latency: 
			99% of requests < 0.5 seconds
			90% of requests < 0.3 seconds
			50% of all requests < 0.2 seconds

        Availability:
            99%

		Error Rate:
			99%
			
Rationale:
	Measure these things and see if our SLIs and SLOs make sense, then use this measurement to justify and iterate SLOs.
	As we do not have the ability to fully load test our service, our targets are based on our assumptions and measurements.
	All averages are over the last week, because we want to improve performance rapidly within an agile development methodology.
	However, we do some 1 hour calculations as well in the interests of monitoring CI/CD.
	
Error Budget:
	Every SLO has its own error budget. We do not have a good projection for the number of requests, but we assume 5000.
	We define the error budget by:
	    100% - % goal per SLO, relative to traffic volume.
        5000 -

    Example:
        API latency SLO of 99% of requests under 1000ms,
         5000 - 99% = Error budget of 50.
         This means up to 50 requests above 1000ms before error budget policy must be applied.
	
Stakeholder agreement:
	Product manager:
		Talk to ben about this and see if he agrees that these standards make sense.
	Developers:
		Decide amongst ourselves if we can maintain this level of service.
	SREs:	
		Decide amongst ourselves as SREs if we can maintain this level of service.
		
Error Budget Policy:
	If we exceed our error budget, what do we do?
		Manager: provision more financial resources for AWS or developer time
		Devs: devote more time to fixing bugs
		Devs: freeze new features
		SRE: Latency high? Provision faster servers/databases.
		
Dashboard:
	API:
		Latency
		Availability
		Throughput //didn't implement
		Error Rate
		Burn Rate
		Error Budget for each
	Database:
		Latency
		Availability
		Error Rate
		Error Budget for each